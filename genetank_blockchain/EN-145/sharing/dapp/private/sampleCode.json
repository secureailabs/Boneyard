{
    "Alzheimers":{
        "datafiles":[
            "duke_50g.csv",
            "wa_50g.csv"
        ],
        "hubcode":[
            "# SAIL's federated learning library",
            "import federated as fd",
            "# Other libraries needed for machine learning",
            "import pandas as pd",
            "import numpy as np",
            "from sklearn.model_selection import train_test_split ",
            "from sklearn.linear_model import LinearRegression",
            "from sklearn import metrics",
            "import csv",
            "",
            "# import matplotlib.pyplot as plt",
            "# import seaborn as sns",
            "#%matplotlib inline",
            "",
            "print(\"Let's do Alzheimers research!\")",
            "",
            "for iteration in range(1):",
            "    fd.startCycle(\"$$ProjectName$$\")",
            "    cnt=0",
            "    size=0",
            "    d = {'Attribute': [], 'Coefficient': []}",
            "    average_coeffs = pd.DataFrame(data=d)",
            "    while cnt<2:",
            "        result=fd.retrieveData()",
            "        cnt = cnt + 1",
            "        if result is not None:",
            "        #     if cnt == 1: ",
            "        #         size += result[0]",
            "        #         average_coeffs = result[1]*result[0] #adding the weighted average",
            "        #     else:",
            "        #         size += result[0]",
            "        #         average_coeffs += result[1]*result[0] #adding the weighted average",
            "          if cnt == 1:",
            "            print(result[0])",
            "            size += result[0]",
            "            average_coeffs['Attribute'] = result[1]['Attribute']",
            "            average_coeffs['Coefficient'] = result[1]['Coefficient']*result[0]",
            "          else:",
            "            print(result[0])",
            "            size += result[0]",
            "            average_coeffs['Coefficient'] = result[1]['Coefficient']*result[0]",
            "            ",
            "      ",
            "    # Dividing coefficients for the weighted average",
            "    if (size>0):",
            "        average_coeffs['Coefficient'] /= size",
            "    print(\"Total number of patients\", size)",
            "    print(\"Average association coefficient is \", average_coeffs)",
            "    ",
            "    average_coeffs.to_csv('/tmp/coef.csv', index=False)",
            "    # f = open(\"/tmp/coef.csv\",'w')",
            "    # f.write(average_coeffs.to_string())",
            "    # f.close()",
            "    "
        ],
        "subcode":[
            "# SAIL's federated learning library",
            "import federated as fd",
            "",
            "# Other libraries needed for machine learning",
            "import pandas as pd",
            "import numpy as np",
            "from sklearn.model_selection import train_test_split ",
            "from sklearn.linear_model import LinearRegression",
            "from sklearn import metrics",
            "",
            "# Preprocess patient EHR",
            "duke = pd.read_csv(\"/data/sharedin/$$dataSetFile$$\")",
            "# duke = pd.read_csv(\"$$dataSetFile$$\")",
            "num_duke_patients = duke.shape[0]",
            "X_duke = duke.drop(['ID_REF','Alzheimers'], axis=1)",
            "y_duke = duke.drop(duke.columns.difference(['Alzheimers']), 1)",
            "",
            "# Run Linear Regression to find the genes of interest",
            "linear_reg_duke = LinearRegression()",
            "linear_reg_duke.fit(X_duke,y_duke)",
            "y_pred_duke = linear_reg_duke.predict(X_duke)",
            "",
            "# Sorting genes most associated with the disease",
            "to_sort_duke=np.column_stack((list(duke.columns[2:]),linear_reg_duke.coef_[0].astype(np.object)))",
            "sorted_desc_duke=to_sort_duke[to_sort_duke[:,1].argsort()][::-1]",
            "",
            "# Train",
            "X_train_duke, X_test_duke, y_train_duke, y_test_duke = train_test_split (X_duke, y_duke, test_size=0.2, random_state=5)",
            "linear_reg_duke = LinearRegression()",
            "linear_reg_duke.fit(X_train_duke,y_train_duke)",
            "",
            "#The coefficients that the model has chosen:",
            "v = pd.DataFrame(linear_reg_duke.coef_,index=['Coefficient']).transpose()",
            "w = pd.DataFrame(X_duke.columns, columns=['Attribute'])",
            "coeff_duke = pd.concat([w,v], axis=1, join='inner')",
            "",
            "# Submitting Data from the subenclave to the hub enclave",
            "fd.submitData([num_duke_patients, coeff_duke])",
            "# fd.submitData([\"num_duke_patients\", \"coeff_duke\"])",
            ""
        ]
    },
    "AD_demo_20200515":{
        "datafiles":[
            "oasis_longitudinal_prepared_h1.csv",
            "oasis_longitudinal_prepared_h2.csv"
        ],
        "hubcode":[
            "# SAIL's federated learning library",
            "import federated as fd",
            "",
            "# Other libraries needed for machine learning",
            "import pandas as pd",
            "import numpy as np",
            "from sklearn.model_selection import train_test_split ",
            "from sklearn.linear_model import LinearRegression",
            "from sklearn import metrics",
            "import csv",
            "",
            "print(\"Let's do Alzheimers research!\")",
            "",
            "for iteration in range(1):",
            "    fd.startCycle(\"$$ProjectName$$\")",
            "    cnt=0",
            "    size=0",
            "    d = {'Attribute': [], 'Coefficient': []}",
            "    average_coeffs = pd.DataFrame(data=d)",
            "    while cnt<2:",
            "        result=fd.retrieveData()",
            "        cnt = cnt + 1",
            "        if result is not None:",
            "          if cnt == 1:",
            "            print(result[0])",
            "            size += result[0]",
            "            average_coeffs['Attribute'] = result[1]['Attribute']",
            "            average_coeffs['Coefficient'] = result[1]['Coefficient']*result[0]",
            "          else:",
            "            print(result[0])",
            "            size += result[0]",
            "            average_coeffs['Coefficient'] = result[1]['Coefficient']*result[0]",
            "            ",
            "      ",
            "    # Dividing coefficients for the weighted average",
            "    if (size>0):",
            "        average_coeffs['Coefficient'] /= size",
            "    print(\"Total number of patients\", size)",
            "    print(\"Average association coefficient is \", average_coeffs)",
            "    ",
            "    average_coeffs.to_csv('/tmp/logreg_coeff.csv', index=False)",
            "    # f = open(\"/tmp/coef.csv\",'w')",
            "    # f.write(average_coeffs.to_string())",
            "    # f.close()",
            "   "
        ],
        "subcode": [
            "# SAIL's federated learning library",
            "import federated as fd",
            "",
            "# Other libraries needed for machine learning",
            "import pandas as pd  ",
            "import numpy as np  ",
            "from sklearn.linear_model import LogisticRegression",
            "from sklearn.svm import SVC",
            "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_curve, auc",
            "from sklearn.model_selection import train_test_split",
            "from sklearn import preprocessing",
            "from sklearn.preprocessing import MinMaxScaler ",
            "from sklearn.model_selection import cross_val_score",
            "",
            "# Preprocess patient EHR",
            "h1 = pd.read_csv('/data/sharedin/$$dataSetFile$$')",
            "",
            "# FL",
            "# Dataset with imputation",
            "Y1 = h1['Group'].values # Target for the model",
            "X1 = h1[['M/F', 'Age', 'EDUC', 'SES', 'MMSE', 'eTIV', 'nWBV', 'ASF']] # Features we use",
            "",
            "# splitting into three sets",
            "X1_trainval, X1_test, Y1_trainval, Y1_test = train_test_split(",
            "    X1, Y1, random_state=0)",
            "",
            "# Feature scaling",
            "scaler1 = MinMaxScaler().fit(X1_trainval)",
            "X1_trainval_scaled = scaler1.transform(X1_trainval)",
            "X1_test_scaled = scaler1.transform(X1_test)",
            "",
            "acc1 = [] # list to store all performance metric",
            "",
            "# Dataset with imputation",
            "",
            "# Build a model on the combined training and validation set",
            "SelectedLogRegModel1 = LogisticRegression(C=10, solver='liblinear').fit(X1_trainval_scaled, Y1_trainval)",
            "test_score1 = SelectedLogRegModel1.score(X1_test_scaled, Y1_test)",
            "PredictedOutput1 = SelectedLogRegModel1.predict(X1_test_scaled)",
            "test_recall1 = recall_score(Y1_test, PredictedOutput1, pos_label=1)",
            "fpr1, tpr1, thresholds1 = roc_curve(Y1_test, PredictedOutput1, pos_label=1)",
            "test_auc1 = auc(fpr1, tpr1)",
            "",
            "m1 = 'Hospital 1: Logistic Regression'",
            "acc1.append([m1, test_score1, test_recall1, test_auc1, fpr1, tpr1, thresholds1])",
            "",
            "# FL",
            "v1 = pd.DataFrame(SelectedLogRegModel1.coef_,index=['Coefficient']).transpose()",
            "w1 = pd.DataFrame(X1.columns, columns=['Attribute'])",
            "coeff_MIR1 = pd.concat([w1,v1], axis=1, join='inner')",
            "",
            "# Submitting Data from the subenclave to the hub enclave",
            "fd.submitData([len(X1), coeff_MIR1])",
            ""
        ]
    }
}
